{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IIT-I HeartRate",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d5AprGFGEem"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KtdhuvOgGMV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject39_1526417507/1526417507.csv', header = None)\n",
        "data = data.T\n",
        "data2 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject39_1526591202/1526591202.csv', header = None)\n",
        "data2 = data2.T\n",
        "data3 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject42_1527280030/1527280030.csv', header = None)\n",
        "data3 = data3.T\n",
        "data4 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject43_1527806941/1527806941.csv', header = None)\n",
        "data4 = data4.T\n",
        "data5 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject54_1539288817/1539288817.csv', header = None)\n",
        "data5 = data5.T\n",
        "data6 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject55_1539459892/1539459892.csv', header = None)\n",
        "data6 = data6.T\n",
        "traindata = pd.concat([data,data2,data3,data4,data5,data6],ignore_index = True)"
      ],
      "metadata": {
        "id": "-l7hYViZGie0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject39_1526417507/heartrates.csv', header = None)\n",
        "data = data.T\n",
        "data = data.drop(0)\n",
        "data2 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject39_1526591202/heartrates.csv', header = None)\n",
        "data2 = data2.T\n",
        "data2 = data2.drop(0)\n",
        "data3 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject42_1527280030/heartrates.csv', header = None)\n",
        "data3 = data3.T\n",
        "data3 = data3.drop(0)\n",
        "data4 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject43_1527806941/heartrates.csv', header = None)\n",
        "data4 = data4.T\n",
        "data4 = data4.drop(0)\n",
        "data5 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject54_1539288817/heartrates.csv', header = None)\n",
        "data5 = data5.T\n",
        "data5 = data5.drop(0)\n",
        "data6 = pd.read_csv('/content/drive/MyDrive/hackathon/ground_truth/Subject55_1539459892/heartrates.csv', header = None)\n",
        "data6 = data6.T\n",
        "data6 = data6.drop(0)\n",
        "target_values = pd.concat([data,data2,data3,data4,data5,data6],ignore_index = True)"
      ],
      "metadata": {
        "id": "Ss0VCxzeLvbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.lstm = nn.LSTM(input_size = 6780, hidden_size = 512, batch_first = True)\n",
        "    self.linear1 = nn.Linear(512, 64)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.linear2 = nn.Linear(64, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_t, c_t = self.lstm(x)\n",
        "    h_t = h_t.squeeze()\n",
        "    res = self.linear1(h_t)\n",
        "    res = self.relu(res)\n",
        "    res = self.dropout(res)\n",
        "    res = self.linear2(res)\n",
        "    res = res.T\n",
        "    return res"
      ],
      "metadata": {
        "id": "CaL8c1xKGqQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeartRateDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, train_data, targets = None):\n",
        "    self.train_data = train_data\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.train_data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if True:\n",
        "      try:\n",
        "        train, targ = self.train_data.loc[idx], self.targets.loc[idx]\n",
        "      except:\n",
        "        train, targ = self.train_data.iloc[idx], self.targets.iloc[idx]\n",
        "      train = train.values.reshape((1,len(train)))\n",
        "      targ = targ.values.reshape((1,len(targ)))\n",
        "      train = train.astype(np.float32)\n",
        "      targ = targ.astype(np.float32)\n",
        "      train = torch.tensor(train)\n",
        "      targ = torch.tensor(targ)\n",
        "      train = train.view((1, 8, 6780))\n",
        "      return train, targ\n",
        "    else:\n",
        "      try:\n",
        "        train = self.train_data.loc[idx]\n",
        "      except:\n",
        "        train = self.train_data.iloc[idx]\n",
        "      train = train.values.reshape((1,len(train)))\n",
        "      train = train.astype(np.float32)\n",
        "      train = torch.tensor(train)\n",
        "      train = train.view((1, 8, 6780))\n",
        "      return train"
      ],
      "metadata": {
        "id": "Z9dEo_LDHBJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, validation_data, train_target, validation_target = train_test_split(traindata, target_values, test_size=1/6, shuffle=False)"
      ],
      "metadata": {
        "id": "09nvGsjucpdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = HeartRateDataset(train_data, train_target)\n",
        "validation_dataset = HeartRateDataset(validation_data, validation_target)"
      ],
      "metadata": {
        "id": "73FqvtXvMc0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 1)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 1)"
      ],
      "metadata": {
        "id": "8KmI6ZXtMhwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, lossfn, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    training_error = 0\n",
        "    for t, (xb, yb) in enumerate(train_dataloader):\n",
        "        xb = xb.to(device, dtype = torch.float32)\n",
        "        yb = yb.to(device, dtype = torch.float32)\n",
        "        xb = xb.squeeze(0)\n",
        "        yb = yb.squeeze()\n",
        "        predictions = model(xb)\n",
        "        predictions = predictions.T\n",
        "        predictions = predictions.to(device, dtype = torch.float32)\n",
        "        #for i in range(8):\n",
        "        #    if yb[i] == -1:\n",
        "        #      predictions[i][0] = -1\n",
        "        loss = lossfn(predictions, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        training_error += torch.sqrt(torch.sum(torch.square(predictions.view(8)-yb))/8)\n",
        "        #training_error += torch.sum(torch.square(predictions.view(8) - yb))\n",
        "    print(f\"Training RMSE: {training_error/5}\")\n",
        "    #scheduler.step(loss)\n",
        "    del loss,predictions\n",
        "    return training_error\n",
        "        \n",
        "def validate(model, lossfn, optimizer, scheduler, device):\n",
        "    validation_error = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for v, (xv, yv) in enumerate(validation_dataloader):\n",
        "            xv = xv.to(device, dtype = torch.float32)\n",
        "            yv = yv.to(device, dtype = torch.int64)\n",
        "            xv = xv.squeeze(0)\n",
        "            yv = yv.squeeze()\n",
        "            predictions = model(xv)\n",
        "            predictions = predictions.T\n",
        "            predictions = predictions.to(device, dtype = torch.float32)\n",
        "            loss = lossfn(predictions, yv)\n",
        "            validation_error += torch.sqrt(torch.sum(torch.square(predictions.view(8) - yv))/8)\n",
        "    print(f\"Validation RMSE: {validation_error/1}\")\n",
        "    return validation_error\n"
      ],
      "metadata": {
        "id": "BJ9kYclxSeYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "n9YEGIx6mIDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM()\n",
        "lossfn = torch.nn.functional.mse_loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
        "scheduler = None\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, threshold=1e-2, verbose = True)"
      ],
      "metadata": {
        "id": "NnbYttcsfQkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "model.to(device)\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch: {i+1}\")\n",
        "    training_error = train(model, lossfn, optimizer, scheduler, device)\n",
        "    validation_error = validate(model, lossfn, optimizer, scheduler, device)"
      ],
      "metadata": {
        "id": "qaqSu4wTZrQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "for i in range(epochs):\n",
        "    print(f\"Epoch: {i+1}\")\n",
        "    training_error = train(model, lossfn, optimizer, scheduler, device)\n",
        "    validation_error = validate(model, lossfn, optimizer, scheduler, device)"
      ],
      "metadata": {
        "id": "BzadOMKCCHAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZZyl6bEPZqvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for v, (xv, yv) in enumerate(train_dataloader):\n",
        "        xv = xv.to(device, dtype = torch.float32)\n",
        "        yv = yv.to(device, dtype = torch.int64)\n",
        "        xv = xv.squeeze(0)\n",
        "        yv = yv.squeeze()\n",
        "        predictions = model(xv)\n",
        "        predictions = predictions.T\n",
        "        predictions = predictions.to(device, dtype = torch.float32)\n",
        "        print(predictions)\n",
        "        print(yv)"
      ],
      "metadata": {
        "id": "ehJjldtlTgy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for v, (xv, yv) in enumerate(validation_dataloader):\n",
        "        xv = xv.to(device, dtype = torch.float32)\n",
        "        yv = yv.to(device, dtype = torch.int64)\n",
        "        xv = xv.squeeze(0)\n",
        "        yv = yv.squeeze()\n",
        "        predictions = model(xv)\n",
        "        predictions = predictions.T\n",
        "        predictions = predictions.to(device, dtype = torch.float32)\n",
        "        print(predictions)\n",
        "        print(yv)"
      ],
      "metadata": {
        "id": "ZPuVigQnUDcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "wkuv1TTnjlQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_values "
      ],
      "metadata": {
        "id": "gdG5qh7zjno5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, train_data, targets = None):\n",
        "    self.train_data = train_data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.train_data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    try:\n",
        "      train = self.train_data.loc[idx]\n",
        "    except:\n",
        "      train = self.train_data.iloc[idx]\n",
        "    train = train.values.reshape((1,len(train)))\n",
        "    train = train.astype(np.float32)\n",
        "    train = torch.tensor(train)\n",
        "    train = train.view((1, 8, 6780))\n",
        "    return train"
      ],
      "metadata": {
        "id": "23IUL5ijEyiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "df = pd.DataFrame()\n",
        "addresses = []\n",
        "for root, dir, files in os.walk('/content/drive/MyDrive/hackathon/dataset'):\n",
        "  if files == []:\n",
        "    pass\n",
        "  else:\n",
        "    path = os.path.join(root, files[0])\n",
        "    data = pd.read_csv(path, header = None)\n",
        "    addresses.append(root)    \n",
        "    data = data.T\n",
        "    df = pd.concat([df,data], ignore_index = True)"
      ],
      "metadata": {
        "id": "HAnnf0groDz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestDataset(df)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "Y-EFm6tRGeqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "        model.eval()\n",
        "        for v, xv in enumerate(test_dataloader):\n",
        "          xv = xv.to(device, dtype = torch.float32)\n",
        "          xv = xv.squeeze(0)\n",
        "          predictions = model(xv).view(8)\n",
        "          predictions = predictions.detach().cpu().numpy()\n",
        "          predictions = np.round(predictions, 2)\n",
        "          path = addresses[v]\n",
        "          time = int(path[-10:])\n",
        "          timestamps = np.arange(time, time+240, 30)\n",
        "          predictionsdf = pd.DataFrame([timestamps,predictions])\n",
        "          predictionsdf = predictionsdf.transpose()\n",
        "\n",
        "          submission = predictionsdf.to_csv(os.path.join(path,'heartrates.csv'), index = False, header = None)\n"
      ],
      "metadata": {
        "id": "u6RvrLceGk_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictionsdf"
      ],
      "metadata": {
        "id": "EMxFEMYrG8b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ahvU9N5HU1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}